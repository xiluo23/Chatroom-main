# C++ 高性能集群聊天服务器 - 面试问题准备

这份文档整理了针对该项目在面试中可能遇到的核心技术问题、代码实现细节及优化方案。

---

## 1. 架构与并发模型 (Architecture & Concurrency)

### Q1: 请介绍一下你这个项目的整体架构？
**参考回答**: 
本项目采用 **Reactor 设计模式**，基于 **Linux Epoll** 实现高并发 I/O 复用。整体架构分为三层：
1.  **接入层 (Reactor)**: 主线程运行 `epoll_wait`，专门负责监听连接请求 (`accept`) 和网络读写事件 (`recv`/`send`)。
2.  **逻辑层 (Business Logic)**: 收到数据后，将其封装为 `Task` 对象放入 **线程池 (ThreadPool)** 的任务队列中。
3.  **数据层 (Data)**: 工作线程从队列取任务，进行业务逻辑处理（如登录、注册、聊天），并通过 **MySQL 连接池** 存取数据，使用 **Redis** 发布/订阅实现跨服务器的消息路由。

### Q2: 你的服务器使用的是 Epoll 的 LT (Level Triggered) 还是 ET (Edge Triggered) 模式？为什么？
**代码现状**: 
*   代码中 `set_unblocking` 函数注释提到了“为ET触发”，且数据读取使用了 `while(1)` 循环读取直到 `EAGAIN`，这是典型的 ET 模式编程风格。
*   但在 `handle_new_connect` 中注册事件时（`epoll_ser.cpp` 第160行），使用的是 `EPOLLIN | EPOLLRDHUP`，**没有显式设置 EPOLLET**。
**参考回答**:
"目前代码默认运行在 **LT (水平触发)** 模式下。虽然我在读取数据时采用了适配 ET 的方式（循环读取直到 `EAGAIN`），以确保一次性读完缓冲区的所有数据，但在注册事件时保留了 LT 模式。这样做的好处是 LT 模式更不易出错（不会丢失事件），同时配合非阻塞循环读取也能获得较高的效率。如果需要极致性能，可以随时加上 `EPOLLET` 标志切换到 ET 模式。"

### Q3: 你的线程池是如何设计的？为什么要用线程池？
**参考回答**:
*   **设计**: 我实现了一个基于 `生产者-消费者模型` 的线程池。包含一个任务队列 (`queue<Task>`)、互斥锁 (`pthread_mutex`) 和条件变量 (`pthread_cond`)。
*   **工作流**: 主线程（生产者）收到网络包后，将请求封装成 `Task` 入队并 `signal` 唤醒工作线程。工作线程（消费者）竞争获取任务并执行。
*   **为什么用**: 
    1.  **避免频繁创建/销毁线程的开销**: 预先创建好固定数量（如 64 个）的线程复用。
    2.  **削峰填谷**: 当并发请求突增时，任务队列起到缓冲作用，防止系统过载。

---

## 2. 网络编程细节 (Network Programming)

### Q4: 如何处理 TCP 粘包 (Sticky Packets) 和拆包问题？
**参考回答**:
我在应用层定义了明确的消息协议（Header + Body）。
1.  **接收缓冲**: 为每个客户端维护一个 `ClientBuffer` 结构（包含缓冲区和当前位置指针）。
2.  **Reactor 读取**: 在 `handle_clint_data` 中，将 socket 数据读取并追加到该客户端的 `ClientBuffer` 中。
3.  **解析线程**: 我专门设计了一个 `Parser` 线程（或逻辑），不断检查 `ClientBuffer`。根据协议头部的长度字段，判断缓冲区是否包含一个完整的包。
    *   如果是完整包 -> 取出并生成 Task。
    *   如果不完整 -> 等待下一次数据到来。
    *   如果有多个包 -> 循环取出。
**代码位置**: `epoll_ser.h` 中的 `ClientBuffer` 结构体及 `parser_thread_func`。

### Q5: 为什么在读取数据时要用 `while(1)` 循环？
**参考回答**:
因为通过 `fcntl` 将 socket 设置为了 **非阻塞 (O_NONBLOCK)** 模式。
在非阻塞模式下，`recv` 不会等待，而是有多少读多少。为了保证把内核缓冲区的数据一次性读完（减少触发 epoll 的次数，提升效率），必须循环调用 `recv`，直到返回 -1 且 `errno == EAGAIN` 或 `EWOULDBLOCK`，这表示“当前暂时无数据可读”。

---

## 3. 数据库与存储 (Database & Storage)

### Q6: 数据库连接池是如何实现的？有什么好处？
**参考回答**:
*   **实现**: 在 `ThreadPool` 初始化时，预先创建了与线程数（如 64 个）相等的 `MyDb` 连接对象，存入 `queue<MyDb*> db_pool`。
*   **获取与归还**: 工作线程需要操作数据库时，从队列头部取出一个连接（加锁），用完后放回队列尾部（解锁）。我还封装了 `DbConnectionGuard` 利用 RAII 机制自动归还连接，防止异常导致连接泄漏。
*   **好处**: 建立 MySQL 连接是昂贵的（涉及 TCP 三次握手和权限验证）。连接池复用了连接，极大降低了每个请求的延迟。

### Q7: Redis 在项目中起什么作用？
**参考回答**:
Redis 主要用于 **跨服务器通信**（虽然目前测试环境可能是单机）。
当用户 A 在服务器 1，用户 B 在服务器 2 时，A 发送的消息无法直接通过内存传递给 B。
我利用 Redis 的 **Pub/Sub (发布/订阅)** 机制：
*   每个用户上线时，订阅一个以自己 UserID 命名的 Channel。
*   当需要发消息给 B 时，如果 B 不在当前服务器内存中，就向 B 的 Channel `publish` 消息。
*   B 所在的服务器收到订阅通知后，再将消息推送到 B 的 socket。

---

## 4. 疑难排查与优化 (Troubleshooting & Optimization)

### Q8: 在压测时遇到了什么问题？是如何解决的？
**参考回答**:
**问题**: 在高并发测试时，发现客户端连接数达到 **2020** 左右就无法继续增加，新连接注册失败。
**排查过程**:
1.  **检查 ulimit**: 最初怀疑是系统文件描述符限制，通过 `ulimit -n` 查看并修改了限制，代码中也添加了 `setrlimit` 自动提升限制。
2.  **排查数据库**: 发现日志中大量数据库操作超时。分析发现原线程池只有 32 个线程，而 MySQL 连接池大小与线程数绑定。当 2000+ 用户同时注册/登录时，数据库连接成为瓶颈。
3.  **线程安全**: 在排查日志时还发现部分广播消息乱码，定位到 `strtok` 函数不是线程安全的，导致多线程环境下解析 UserID 列表出错。
**解决方案**:
1.  将线程池和数据库连接池扩大到 **64**。
2.  将 `strtok` 替换为线程安全的 **`strtok_r`**。
3.  优化了 `ulimit` 设置逻辑。

### Q9: 为什么使用 `strtok_r` 而不是 `strtok`？
**参考回答**:
`strtok` 使用一个内部静态指针来保存解析状态，这在多线程环境下是不安全的（一个线程的解析状态会被另一个线程覆盖）。
`strtok_r` 是 **Reentrant (可重入)** 版本，它要求调用者自己提供一个 `saveptr` 指针来维护状态。在我的 `broadcast_chat` 业务中，多个线程可能同时处理广播请求，必须使用 `strtok_r` 保证每个线程的解析上下文独立，防止数据错乱。

---

## 5. C++ 语言细节 (C++ Specifics)

### Q10: 项目中用到了哪些 C++11/14 特性？
*   `auto`: 自动类型推导（迭代器遍历）。
*   `std::function` & `std::bind` (如果有用到回调)。
*   `std::thread` / `pthread`: 多线程支持。
*   `std::mutex` / `std::lock_guard`: 虽然代码用了 `pthread_mutex`，但概念是一致的。
*   `std::string`: 方便的字符串处理。
*   `std::vector`, `std::queue`, `std::unordered_map`: STL 容器的使用。
